import os
import torch
import pandas as pd
from sentence_transformers import SentenceTransformer
import sys

# ================= é…ç½®åŒºåŸŸ =================
# 1. åŸºç¡€è·¯å¾„ (æ ¹æ®æ‚¨çš„ dataset.py æ¨æ–­)
BASE_DATA_DIR = '../data/ML1M'

# 2. å…³é”®æ–‡ä»¶è·¯å¾„
# [è¾“å…¥] åŸå§‹å…ƒæ•°æ® (æ ¼å¼: MovieID::Title::Genres)
# æ³¨æ„ï¼šMovieLens æ•°æ®é›†é€šå¸¸åœ¨è§£å‹åçš„ ml-1m æ–‡ä»¶å¤¹é‡Œï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µç¡®è®¤
# å¦‚æœæ‚¨çš„ movies.dat ç›´æ¥åœ¨ ML1M ä¸‹ï¼Œè¯·ç”¨ç¬¬ä¸€è¡Œï¼›å¦‚æœåœ¨å­ç›®å½•ï¼Œè¯·ç”¨ç¬¬äºŒè¡Œ
RAW_META_FILE = os.path.join(BASE_DATA_DIR, 'movies.dat')
# RAW_META_FILE = os.path.join(BASE_DATA_DIR, 'ml-1m', 'movies.dat')

# [è¾“å…¥] éœ€è¦ä¿®å¤çš„ Item List (å½“å‰åŒ…å« "org_id remap_id" è¡¨å¤´)
BAD_ITEM_LIST = os.path.join(BASE_DATA_DIR, 'item_list.txt')

# [è¾“å‡º] ä¿®å¤åçš„çº¯æ–‡æœ¬æ–‡ä»¶
OUTPUT_TEXT_FILE = os.path.join(BASE_DATA_DIR, 'item_list_fixed.txt')
# [è¾“å‡º] ç”Ÿæˆçš„è¯­ä¹‰å‘é‡æ–‡ä»¶
OUTPUT_EMB_FILE = os.path.join(BASE_DATA_DIR, 'semantic_emb.pt')

# 3. æ¨¡å‹é…ç½®
# å»ºè®®ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œæˆ–è€…ä½¿ç”¨ HuggingFace åœ¨çº¿æ¨¡å‹åç§° (å¦‚ 'all-MiniLM-L6-v2')
# å¦‚æœæ‚¨ä¹‹å‰ç”¨çš„æ˜¯ sentence-t5-baseï¼Œè¯·ç¡®ä¿è·¯å¾„æ­£ç¡®
MODEL_PATH = '../src/sentence-t5-base'
# å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šä½¿ç”¨åœ¨çº¿æ¨¡å‹ï¼š
# MODEL_PATH = 'sentence-transformers/all-MiniLM-L6-v2'

device = 'cuda' if torch.cuda.is_available() else 'cpu'


# ===========================================

def check_paths():
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(RAW_META_FILE):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å…ƒæ•°æ®æ–‡ä»¶: {RAW_META_FILE}")
        print("   -> è¯·ç¡®è®¤ movies.dat æ˜¯å¦åœ¨ data/ML1M/ ç›®å½•ä¸‹ï¼Œæˆ–è€…åœ¨ data/ML1M/ml-1m/ ä¸‹ã€‚")
        sys.exit(1)
    if not os.path.exists(BAD_ITEM_LIST):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° item_list.txt: {BAD_ITEM_LIST}")
        sys.exit(1)
    print("âœ… è·¯å¾„æ£€æŸ¥é€šè¿‡ã€‚")


def load_movie_meta():
    """
    è¯»å– ML1M movies.dat
    æ ¼å¼: MovieID::Title::Genres
    ç¼–ç : Latin-1
    """
    print(f"æ­£åœ¨è¯»å–åŸå§‹å…ƒæ•°æ®: {RAW_META_FILE}")
    meta_dict = {}

    try:
        # ä½¿ç”¨ python å¼•æ“å¤„ç†å¤šå­—ç¬¦åˆ†éš”ç¬¦ '::'
        # MovieLens é€šå¸¸æ˜¯ Latin-1 ç¼–ç 
        df = pd.read_csv(RAW_META_FILE, sep='::', header=None,
                         names=['id', 'title', 'genres'],
                         engine='python', encoding='latin-1')

        for _, row in df.iterrows():
            # æ•°æ®æ¸…æ´—: å°†æµæ´¾ä¸­çš„ '|' æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œå¢åŠ è¯­ä¹‰å¯è¯»æ€§
            # ä¾‹å¦‚: "Animation|Children's" -> "Animation Children's"
            clean_genres = str(row['genres']).replace('|', ' ')

            # ç»„åˆæ–‡æœ¬: Title + Genres
            # ä¾‹å¦‚: "Toy Story (1995) Animation Children's Comedy"
            full_text = f"{row['title']} {clean_genres}"

            # å­˜å…¥å­—å…¸: str(ID) -> Text
            meta_dict[str(row['id'])] = full_text

        print(f"âœ… å…ƒæ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(meta_dict)} éƒ¨ç”µå½±ä¿¡æ¯ã€‚")
        return meta_dict

    except Exception as e:
        print(f"âŒ è¯»å– movies.dat å¤±è´¥: {e}")
        sys.exit(1)


def fix_item_list(meta_dict):
    """
    è¯»å–åçš„ item_list.txt (å¸¦è¡¨å¤´, æ ¼å¼: org_id remap_id)
    ç”Ÿæˆå¥½çš„ item_list_fixed.txt (çº¯æ–‡æœ¬)
    """
    print(f"\nSTEP 1: ä¿®å¤ Item List æ–‡æœ¬")

    fixed_lines = []
    missing_count = 0

    with open(BAD_ITEM_LIST, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    print(f"åŸå§‹æ–‡ä»¶å…± {len(lines)} è¡Œã€‚")

    # æ£€æµ‹å¹¶è·³è¿‡è¡¨å¤´
    start_idx = 0
    if len(lines) > 0 and "org_id" in lines[0]:
        print("â„¹ï¸ æ£€æµ‹åˆ°è¡¨å¤´ 'org_id'ï¼Œå·²è·³è¿‡ç¬¬ä¸€è¡Œã€‚")
        start_idx = 1

    # éå†å¤„ç†
    for i in range(start_idx, len(lines)):
        line = lines[i].strip()
        if not line: continue

        parts = line.split()
        # ç¬¬ä¸€åˆ—é€šå¸¸æ˜¯ org_id
        org_id = parts[0]

        if org_id in meta_dict:
            real_text = meta_dict[org_id]
        else:
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œç”¨å ä½ç¬¦é˜²æ­¢æŠ¥é”™ï¼Œä½†è®°å½•è­¦å‘Š
            real_text = f"Unknown Movie {org_id}"
            missing_count += 1
            if missing_count <= 5:
                print(f"âš ï¸ è­¦å‘Š: ID {org_id} åœ¨ movies.dat ä¸­æœªæ‰¾åˆ°ã€‚")

        fixed_lines.append(real_text)

    # å†™å…¥æ–°æ–‡ä»¶
    with open(OUTPUT_TEXT_FILE, 'w', encoding='utf-8') as f:
        for text in fixed_lines:
            f.write(text + '\n')

    print(f"âœ… æ–‡æœ¬ä¿®å¤å®Œæˆï¼æœ‰æ•ˆç‰©å“æ•°: {len(fixed_lines)}")
    if missing_count > 0:
        print(f"âš ï¸ å…±æœ‰ {missing_count} ä¸ªç‰©å“ç¼ºå¤±å…ƒæ•°æ®ã€‚")

    # é¢„è§ˆå‰å‡ è¡Œ
    print("-" * 30)
    print("é¢„è§ˆå‰ 3 è¡Œå†…å®¹:")
    for k in range(min(3, len(fixed_lines))):
        print(f"[{k}] {fixed_lines[k]}")
    print("-" * 30)

    return fixed_lines


def generate_embeddings(text_list):
    """ä½¿ç”¨ Sentence-Transformer ç”Ÿæˆå‘é‡"""
    print(f"\nSTEP 2: ç”Ÿæˆè¯­ä¹‰å‘é‡ (Semantic Embeddings)")
    print(f"åŠ è½½æ¨¡å‹: {MODEL_PATH}")
    print(f"è¿è¡Œè®¾å¤‡: {device}")

    try:
        model = SentenceTransformer(MODEL_PATH, device=device)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ MODEL_PATH æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•è”ç½‘ä¸‹è½½ 'all-MiniLM-L6-v2'")
        return

    print("å¼€å§‹ç¼–ç  (Encoding)...")
    # ç”Ÿæˆå‘é‡
    embeddings = model.encode(text_list, show_progress_bar=True, convert_to_tensor=True)

    print(f"ç”Ÿæˆçš„ Embedding å½¢çŠ¶: {embeddings.shape}")

    # ä¿å­˜ .pt æ–‡ä»¶
    torch.save(embeddings.cpu(), OUTPUT_EMB_FILE)
    print(f"âœ… å‘é‡å·²ä¿å­˜è‡³: {OUTPUT_EMB_FILE}")


if __name__ == "__main__":
    # 1. æ£€æŸ¥è·¯å¾„
    check_paths()

    # 2. åŠ è½½å…ƒæ•°æ®
    meta_dict = load_movie_meta()

    # 3. ä¿®å¤æ–‡æœ¬åˆ—è¡¨
    clean_texts = fix_item_list(meta_dict)

    # 4. ç”Ÿæˆè¯­ä¹‰å‘é‡
    if clean_texts:
        generate_embeddings(clean_texts)

        print("\nğŸ‰ ====== å…¨éƒ¨å®Œæˆ ======")
        print("è¯·æ‰§è¡Œä»¥ä¸‹æœ€åä¸€æ­¥æ“ä½œï¼š")
        print(f"1. è¿›å…¥ç›®å½•: cd {BASE_DATA_DIR}")
        print(f"2. å¤‡ä»½åŸæ–‡ä»¶ (å¯é€‰): mv item_list.txt item_list.bak")
        print(f"3. æ›¿æ¢æ–°æ–‡ä»¶: mv item_list_fixed.txt item_list.txt")
        print("4. é‡æ–°è¿è¡Œ main.py --vq --train_vq")
