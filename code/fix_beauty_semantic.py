import os
import torch
import gzip
import json
from sentence_transformers import SentenceTransformer
import sys
import ast  # ç”¨äºè§£æéæ ‡å‡† JSON æ ¼å¼

# ================= é…ç½®åŒºåŸŸ =================
BASE_DATA_DIR = '../data/Beauty'
RAW_META_FILE = os.path.join(BASE_DATA_DIR, 'meta_Beauty.json.gz')
BAD_ITEM_LIST = os.path.join(BASE_DATA_DIR, 'item_list.txt')
OUTPUT_TEXT_FILE = os.path.join(BASE_DATA_DIR, 'item_list_fixed.txt')
OUTPUT_EMB_FILE = os.path.join(BASE_DATA_DIR, 'semantic_emb.pt')

MODEL_PATH = '../src/sentence-t5-base'
device = 'cuda' if torch.cuda.is_available() else 'cpu'


# ===========================================

def check_paths():
    if not os.path.exists(RAW_META_FILE):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å…ƒæ•°æ®æ–‡ä»¶: {RAW_META_FILE}")
        sys.exit(1)
    if not os.path.exists(BAD_ITEM_LIST):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° item_list.txt: {BAD_ITEM_LIST}")
        sys.exit(1)
    print("âœ… è·¯å¾„æ£€æŸ¥é€šè¿‡ã€‚")


def load_beauty_meta():
    """åŒæ¨¡è¯»å– Amazon Beauty å…ƒæ•°æ® (å…¼å®¹ JSON å’Œ Python-Eval æ ¼å¼)"""
    print(f"æ­£åœ¨è¯»å–åŸå§‹å…ƒæ•°æ®: {RAW_META_FILE}")
    meta_dict = {}

    count = 0
    success_count = 0

    # ä½¿ç”¨ 'rt' æ¨¡å¼ (Read Text) å¹¶æŒ‡å®š utf-8ï¼Œç¡®ä¿è¯»å‡ºæ¥æ˜¯å­—ç¬¦ä¸²
    with gzip.open(RAW_META_FILE, 'rt', encoding='utf-8') as f:
        for line in f:
            count += 1
            data = None

            # --- æ ¸å¿ƒä¿®å¤ï¼šå°è¯•å¤šç§è§£ææ–¹å¼ ---
            try:
                # æ–¹å¼ 1: æ ‡å‡† JSON
                data = json.loads(line)
            except json.JSONDecodeError:
                try:
                    # æ–¹å¼ 2: Python å­—å…¸æ ¼å¼ (æ—§ç‰ˆ Amazon æ•°æ®é›†)
                    # ä½¿ç”¨ ast.literal_eval æ¯” eval æ›´å®‰å…¨
                    data = ast.literal_eval(line)
                except Exception:
                    pass

            # å¦‚æœè§£æå¤±è´¥ï¼Œæ‰“å°ç¬¬ä¸€è¡ŒæŠ¥é”™ä»¥ä¾¿è°ƒè¯•
            if data is None:
                if count == 1:
                    print(f"âŒ è§£æç¬¬ä¸€è¡Œå¤±è´¥ï¼å†…å®¹é¢„è§ˆ: {line[:100]}...")
                continue

            # æå–æ•°æ®
            try:
                asin = data.get('asin', '')
                title = data.get('title', '')

                # å¢å¼ºè¯­ä¹‰ï¼šå“ç‰Œ + ç±»åˆ«
                brand = data.get('brand', '')
                categories = data.get('categories', [[]])

                # å¤„ç† categories å¯èƒ½æ˜¯åˆ—è¡¨çš„åˆ—è¡¨ [['Beauty', 'Hair Care']]
                cat_str = ""
                if categories and isinstance(categories[0], list):
                    cat_str = " ".join(categories[0])
                elif isinstance(categories, list):
                    cat_str = " ".join(categories)

                full_text = f"{title} {brand} {cat_str}".strip()

                if asin:
                    meta_dict[str(asin)] = full_text
                    success_count += 1
            except Exception:
                continue

    print(f"âœ… å…ƒæ•°æ®åŠ è½½å®Œæˆã€‚")
    print(f"   - æ€»è¡Œæ•°: {count}")
    print(f"   - æˆåŠŸè§£æ: {success_count}")

    if success_count == 0:
        print("âŒ è­¦å‘Šï¼šä¾ç„¶æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æ•°æ®ï¼è¯·æ£€æŸ¥ meta_Beauty.json.gz æ–‡ä»¶æ˜¯å¦æŸåæˆ–ä¸ºç©ºã€‚")
        sys.exit(1)

    return meta_dict


def fix_item_list(meta_dict):
    print(f"\nSTEP 1: ä¿®å¤ Item List æ–‡æœ¬")

    fixed_lines = []
    missing_count = 0

    with open(BAD_ITEM_LIST, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    print(f"åŸå§‹ item_list å…± {len(lines)} è¡Œã€‚")

    # æ£€æµ‹å¹¶è·³è¿‡è¡¨å¤´
    start_idx = 0
    if len(lines) > 0 and "org_id" in lines[0]:
        print("â„¹ï¸ æ£€æµ‹åˆ°è¡¨å¤´ 'org_id'ï¼Œå·²è·³è¿‡ç¬¬ä¸€è¡Œã€‚")
        start_idx = 1

    for i in range(start_idx, len(lines)):
        line = lines[i].strip()
        if not line: continue

        parts = line.split()
        org_id = parts[0]  # ASIN

        if org_id in meta_dict:
            real_text = meta_dict[org_id]
        else:
            real_text = f"Unknown Product {org_id}"
            missing_count += 1
            if missing_count <= 5:
                print(f"âš ï¸ è­¦å‘Š: ASIN {org_id} æœªæ‰¾åˆ°å…ƒæ•°æ®ã€‚")

        fixed_lines.append(real_text)

    # å†™å…¥æ–°æ–‡ä»¶
    with open(OUTPUT_TEXT_FILE, 'w', encoding='utf-8') as f:
        for text in fixed_lines:
            f.write(text + '\n')

    print(f"âœ… æ–‡æœ¬ä¿®å¤å®Œæˆï¼æœ‰æ•ˆç‰©å“æ•°: {len(fixed_lines)}")
    print(f"ç¼ºå¤±å…ƒæ•°æ®æ•°: {missing_count}")

    # é¢„è§ˆ
    print("-" * 30)
    print("é¢„è§ˆå‰ 3 è¡Œå†…å®¹:")
    for k in range(min(3, len(fixed_lines))):
        print(f"[{k}] {fixed_lines[k]}")
    print("-" * 30)

    return fixed_lines


def generate_embeddings(text_list):
    print(f"\nSTEP 2: ç”Ÿæˆè¯­ä¹‰å‘é‡")
    print(f"åŠ è½½æ¨¡å‹: {MODEL_PATH}")

    try:
        model = SentenceTransformer(MODEL_PATH, device=device)
        embeddings = model.encode(text_list, show_progress_bar=True, convert_to_tensor=True)

        print(f"ç”Ÿæˆçš„ Embedding å½¢çŠ¶: {embeddings.shape}")
        torch.save(embeddings.cpu(), OUTPUT_EMB_FILE)
        print(f"âœ… å‘é‡å·²ä¿å­˜è‡³: {OUTPUT_EMB_FILE}")

    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")


if __name__ == "__main__":
    check_paths()
    meta_dict = load_beauty_meta()
    clean_texts = fix_item_list(meta_dict)
    if clean_texts:
        generate_embeddings(clean_texts)
        print("\nğŸ‰ Beauty æ•°æ®ä¿®å¤å®Œæˆï¼")
        print("è¯·æ‰§è¡Œæœ€åä¸€æ­¥ï¼š")
        print("1. è¿›å…¥ data/Beauty ç›®å½•")
        print("2. åˆ é™¤æ—§çš„ item_list.txt")
        print("3. é‡å‘½å item_list_fixed.txt -> item_list.txt")
        print("4. å›åˆ° code ç›®å½•è¿è¡Œ: python main.py --dataset Beauty --vq --train_vq")